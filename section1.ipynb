{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitpy371conda7496ccb775b1428aa3252e94c80a8296",
   "display_name": "Python 3.7.1 64-bit ('py371': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第1章: 準備運動\n",
    "# https://nlp100.github.io/ja/ch01.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "desserts\n"
    }
   ],
   "source": [
    "# 00: 文字列の逆順\n",
    "s1 = \"stressed\"\n",
    "s2 = s1[::-1]\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "パトカー\n"
    }
   ],
   "source": [
    "# 01:「パタトクカシー」\n",
    "s1 = \"パタトクカシー\"\n",
    "s2 = s1[0::2]\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "パタトクカシーー\n"
    }
   ],
   "source": [
    "# 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "s1 = \"パトカー\"\n",
    "s2 = \"タクシー\"\n",
    "s3 = \"\"\n",
    "for c1, c2 in zip(s1, s2):\n",
    "    s3 += c1 + c2\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
    }
   ],
   "source": [
    "# 03. 円周率\n",
    "# “Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．\n",
    "import re\n",
    "s1 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "words = [re.sub(r\"[,.]\", \"\", word) for word in s1.split(\" \")]\n",
    "wordnums = [len(word) for word in words]\n",
    "print(wordnums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Now I need a drink alcoholic of course after the heavy lectures involving quantum mechanics\n"
    }
   ],
   "source": [
    "# 04. 元素記号Permalink\n",
    "# “Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．\n",
    "s1 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "words = re.sub(r\"[,.]\", \"\", s1)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "単語bi-gram\n['Iam', 'aman', 'anNLPer']\n文字bi-gram\n['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
    }
   ],
   "source": [
    "# 05. n-gramPermalink\n",
    "# 与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．\n",
    "import re\n",
    "\n",
    "s1 = \"I am an NLPer\"\n",
    "\n",
    "# 単語区切りのリスト\n",
    "tangos = s1.split(\" \")\n",
    "\n",
    "# 文字のみ抽出した文字列\n",
    "moji = re.sub(r\" \", \"\", s1)\n",
    "\n",
    "def tango_n_gram(n, tangos):\n",
    "    \"\"\"単語N-gram\"\"\"\n",
    "    N = len(tangos)\n",
    "    ans = []\n",
    "    for i in range(N):\n",
    "        if i+n > N: break\n",
    "        ans.append(\"\".join(tangos[i:i+n]))\n",
    "    return ans\n",
    "\n",
    "def moji_n_gram(n, s):\n",
    "    N = len(s)\n",
    "    ans = []\n",
    "    for i in range(N):\n",
    "        if i+n > N: break\n",
    "        ans.append(s[i:i+n])\n",
    "    return ans\n",
    "\n",
    "# 単語bi-gram\n",
    "tango_bi_grams = tango_n_gram(2, tangos)\n",
    "print(\"単語bi-gram\")\n",
    "print(tango_bi_grams)\n",
    "\n",
    "# 文字bi-gram\n",
    "moji_bi_grams = moji_n_gram(2, moji)\n",
    "print(\"文字bi-gram\")\n",
    "print(moji_bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X:  {'ra', 'ap', 'pa', 'di', 'ad', 'is', 'ar', 'se'}\nY:  {'ra', 'gr', 'ap', 'pa', 'ag', 'ph', 'ar'}\n和集合:  {'ra', 'ph', 'gr', 'ap', 'pa', 'di', 'ag', 'ad', 'is', 'ar', 'se'}\n積集合:  {'ap', 'ar', 'pa', 'ra'}\n差集合:  {'ad', 'is', 'di', 'se'}\nexists 'se' in X?:  True\nexists 'se' in Y?:  False\n"
    }
   ],
   "source": [
    "# 06. 集合Permalink\n",
    "# “paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．\n",
    "s1 = \"paraparaparadise\"\n",
    "s2 = \"paragraph\"\n",
    "\n",
    "X = set(moji_n_gram(2, s1))\n",
    "Y = set(moji_n_gram(2, s2))\n",
    "print(\"X: \", X)\n",
    "print(\"Y: \", Y)\n",
    "\n",
    "print(\"和集合: \", X|Y)\n",
    "print(\"積集合: \", X&Y)\n",
    "print(\"差集合: \", X-Y)\n",
    "\n",
    "print(\"exists 'se' in X?: \", \"se\" in X)\n",
    "print(\"exists 'se' in Y?: \", \"se\" in Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12時の気温は22.4\n"
    }
   ],
   "source": [
    "# 07. テンプレートによる文生成Permalink\n",
    "# 引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．\n",
    "def make_template(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "print(make_template(12, \"気温\", 22.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pvinzormp\n"
    }
   ],
   "source": [
    "# 08. 暗号文Permalink\n",
    "# 与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "# ・英小文字ならば(219 - 文字コード)の文字に置換\n",
    "# ・その他の文字はそのまま出力\n",
    "# この関数を用い，英語のメッセージを暗号化・復号化せよ．\n",
    "def cipher(s):\n",
    "    ans = \"\"\n",
    "    for c in s:\n",
    "        if 97 <= ord(c) <= 122:\n",
    "            ans += chr(219-ord(c))\n",
    "        else:\n",
    "            ans += c\n",
    "    return ans\n",
    "\n",
    "s = cipher(\"Permalink\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. TypoglycemiaPermalink\n",
    "# スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．\n",
    "from random import randrange\n",
    "s1 = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "def random_sort(s):\n",
    "    words = s.split(\" \")\n",
    "    ans = []\n",
    "    for w in words:\n",
    "        if len(w) <= 4:\n",
    "            ans.append(w)\n",
    "            continue\n",
    "        ws = list(w)\n",
    "        head = ws.pop(0)\n",
    "        tail = ws.pop(-1)\n",
    "        new = \"\"\n",
    "        while len(ws) != 0:\n",
    "            i = randrange(0, len(ws))\n",
    "            new += ws.pop(i)\n",
    "        new = head + new + tail\n",
    "        ans.append(new)\n",
    "    return \" \".join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['a', 'i', 'u', 'e', 'o']"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": []
  }
 ]
}